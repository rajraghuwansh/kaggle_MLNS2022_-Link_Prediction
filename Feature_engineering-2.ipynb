{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\rkroc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rkroc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import igraph\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.decomposition import TruncatedSVD, NMF\n",
    "from sklearn import preprocessing\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from igraph.clustering import *\n",
    "from time import time\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\rkroc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rkroc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt') # for tokenization\n",
    "nltk.download('stopwords')\n",
    "stpwds = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "\n",
    "with open(\"data/testing_set.txt\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    testing_set  = list(reader)\n",
    "\n",
    "testing_set = [element[0].split(\" \") for element in testing_set]\n",
    "\n",
    "with open(\"data/training_set.txt\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    training_set  = list(reader)\n",
    "\n",
    "training_set = [element[0].split(\" \") for element in training_set]\n",
    "\n",
    "with open(\"data/node_information.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    node_info  = list(reader)\n",
    "IDs = [i[0] for i in node_info]\n",
    "year=[int(i[1]) for i in node_info]\n",
    "title=[i[2] for i in node_info]\n",
    "authors=[i[3] for i in node_info]\n",
    "name_journal=[i[4] for i in node_info]\n",
    "abstract=[i[5] for i in node_info]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_information = pd.read_csv('data/node_information.csv', header=None, names=['ID', 'Year', 'Title', 'Authors', 'Journal', 'Abstract'])\n",
    "train = pd.read_csv('data/training_set.txt', header=None, names=['Source', 'Target', 'Edge'], delim_whitespace=True)\n",
    "test = pd.read_csv('data/testing_set.txt', header=None, names=['Source', 'Target'], delim_whitespace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID             0\n",
       "Year           0\n",
       "Title          0\n",
       "Authors     4033\n",
       "Journal     7472\n",
       "Abstract       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_information.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "## 2. Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2a\"></a>\n",
    "### A1 - Semantic features train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creation of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 training examples processsed\n",
      "1001 training examples processsed\n",
      "2001 training examples processsed\n",
      "3001 training examples processsed\n",
      "4001 training examples processsed\n",
      "5001 training examples processsed\n",
      "6001 training examples processsed\n",
      "7001 training examples processsed\n",
      "8001 training examples processsed\n",
      "9001 training examples processsed\n",
      "10001 training examples processsed\n",
      "11001 training examples processsed\n",
      "12001 training examples processsed\n",
      "13001 training examples processsed\n",
      "14001 training examples processsed\n",
      "15001 training examples processsed\n",
      "16001 training examples processsed\n",
      "17001 training examples processsed\n",
      "18001 training examples processsed\n",
      "19001 training examples processsed\n",
      "20001 training examples processsed\n",
      "21001 training examples processsed\n",
      "22001 training examples processsed\n",
      "23001 training examples processsed\n",
      "24001 training examples processsed\n",
      "25001 training examples processsed\n",
      "26001 training examples processsed\n",
      "27001 training examples processsed\n",
      "28001 training examples processsed\n",
      "29001 training examples processsed\n",
      "30001 training examples processsed\n",
      "31001 training examples processsed\n",
      "32001 training examples processsed\n",
      "33001 training examples processsed\n",
      "34001 training examples processsed\n",
      "35001 training examples processsed\n",
      "36001 training examples processsed\n",
      "37001 training examples processsed\n",
      "38001 training examples processsed\n",
      "39001 training examples processsed\n",
      "40001 training examples processsed\n",
      "41001 training examples processsed\n",
      "42001 training examples processsed\n",
      "43001 training examples processsed\n",
      "44001 training examples processsed\n",
      "45001 training examples processsed\n",
      "46001 training examples processsed\n",
      "47001 training examples processsed\n",
      "48001 training examples processsed\n",
      "49001 training examples processsed\n",
      "50001 training examples processsed\n",
      "51001 training examples processsed\n",
      "52001 training examples processsed\n",
      "53001 training examples processsed\n",
      "54001 training examples processsed\n",
      "55001 training examples processsed\n",
      "56001 training examples processsed\n",
      "57001 training examples processsed\n",
      "58001 training examples processsed\n",
      "59001 training examples processsed\n",
      "60001 training examples processsed\n",
      "61001 training examples processsed\n",
      "62001 training examples processsed\n",
      "63001 training examples processsed\n",
      "64001 training examples processsed\n",
      "65001 training examples processsed\n",
      "66001 training examples processsed\n",
      "67001 training examples processsed\n",
      "68001 training examples processsed\n",
      "69001 training examples processsed\n",
      "70001 training examples processsed\n",
      "71001 training examples processsed\n",
      "72001 training examples processsed\n",
      "73001 training examples processsed\n",
      "74001 training examples processsed\n",
      "75001 training examples processsed\n",
      "76001 training examples processsed\n",
      "77001 training examples processsed\n",
      "78001 training examples processsed\n",
      "79001 training examples processsed\n",
      "80001 training examples processsed\n",
      "81001 training examples processsed\n",
      "82001 training examples processsed\n",
      "83001 training examples processsed\n",
      "84001 training examples processsed\n",
      "85001 training examples processsed\n",
      "86001 training examples processsed\n",
      "87001 training examples processsed\n",
      "88001 training examples processsed\n",
      "89001 training examples processsed\n",
      "90001 training examples processsed\n",
      "91001 training examples processsed\n",
      "92001 training examples processsed\n",
      "93001 training examples processsed\n",
      "94001 training examples processsed\n",
      "95001 training examples processsed\n",
      "96001 training examples processsed\n",
      "97001 training examples processsed\n",
      "98001 training examples processsed\n",
      "99001 training examples processsed\n",
      "100001 training examples processsed\n",
      "101001 training examples processsed\n",
      "102001 training examples processsed\n",
      "103001 training examples processsed\n",
      "104001 training examples processsed\n",
      "105001 training examples processsed\n",
      "106001 training examples processsed\n",
      "107001 training examples processsed\n",
      "108001 training examples processsed\n",
      "109001 training examples processsed\n",
      "110001 training examples processsed\n",
      "111001 training examples processsed\n",
      "112001 training examples processsed\n",
      "113001 training examples processsed\n",
      "114001 training examples processsed\n",
      "115001 training examples processsed\n",
      "116001 training examples processsed\n",
      "117001 training examples processsed\n",
      "118001 training examples processsed\n",
      "119001 training examples processsed\n",
      "120001 training examples processsed\n",
      "121001 training examples processsed\n",
      "122001 training examples processsed\n",
      "123001 training examples processsed\n",
      "124001 training examples processsed\n",
      "125001 training examples processsed\n",
      "126001 training examples processsed\n",
      "127001 training examples processsed\n",
      "128001 training examples processsed\n",
      "129001 training examples processsed\n",
      "130001 training examples processsed\n",
      "131001 training examples processsed\n",
      "132001 training examples processsed\n",
      "133001 training examples processsed\n",
      "134001 training examples processsed\n",
      "135001 training examples processsed\n",
      "136001 training examples processsed\n",
      "137001 training examples processsed\n",
      "138001 training examples processsed\n",
      "139001 training examples processsed\n",
      "140001 training examples processsed\n",
      "141001 training examples processsed\n",
      "142001 training examples processsed\n",
      "143001 training examples processsed\n",
      "144001 training examples processsed\n",
      "145001 training examples processsed\n",
      "146001 training examples processsed\n",
      "147001 training examples processsed\n",
      "148001 training examples processsed\n",
      "149001 training examples processsed\n",
      "150001 training examples processsed\n",
      "151001 training examples processsed\n",
      "152001 training examples processsed\n",
      "153001 training examples processsed\n",
      "154001 training examples processsed\n",
      "155001 training examples processsed\n",
      "156001 training examples processsed\n",
      "157001 training examples processsed\n",
      "158001 training examples processsed\n",
      "159001 training examples processsed\n",
      "160001 training examples processsed\n",
      "161001 training examples processsed\n",
      "162001 training examples processsed\n",
      "163001 training examples processsed\n",
      "164001 training examples processsed\n",
      "165001 training examples processsed\n",
      "166001 training examples processsed\n",
      "167001 training examples processsed\n",
      "168001 training examples processsed\n",
      "169001 training examples processsed\n",
      "170001 training examples processsed\n",
      "171001 training examples processsed\n",
      "172001 training examples processsed\n",
      "173001 training examples processsed\n",
      "174001 training examples processsed\n",
      "175001 training examples processsed\n",
      "176001 training examples processsed\n",
      "177001 training examples processsed\n",
      "178001 training examples processsed\n",
      "179001 training examples processsed\n",
      "180001 training examples processsed\n",
      "181001 training examples processsed\n",
      "182001 training examples processsed\n",
      "183001 training examples processsed\n",
      "184001 training examples processsed\n",
      "185001 training examples processsed\n",
      "186001 training examples processsed\n",
      "187001 training examples processsed\n",
      "188001 training examples processsed\n",
      "189001 training examples processsed\n",
      "190001 training examples processsed\n",
      "191001 training examples processsed\n",
      "192001 training examples processsed\n",
      "193001 training examples processsed\n",
      "194001 training examples processsed\n",
      "195001 training examples processsed\n",
      "196001 training examples processsed\n",
      "197001 training examples processsed\n",
      "198001 training examples processsed\n",
      "199001 training examples processsed\n",
      "200001 training examples processsed\n",
      "201001 training examples processsed\n",
      "202001 training examples processsed\n",
      "203001 training examples processsed\n",
      "204001 training examples processsed\n",
      "205001 training examples processsed\n",
      "206001 training examples processsed\n",
      "207001 training examples processsed\n",
      "208001 training examples processsed\n",
      "209001 training examples processsed\n",
      "210001 training examples processsed\n",
      "211001 training examples processsed\n",
      "212001 training examples processsed\n",
      "213001 training examples processsed\n",
      "214001 training examples processsed\n",
      "215001 training examples processsed\n",
      "216001 training examples processsed\n",
      "217001 training examples processsed\n",
      "218001 training examples processsed\n",
      "219001 training examples processsed\n",
      "220001 training examples processsed\n",
      "221001 training examples processsed\n",
      "222001 training examples processsed\n",
      "223001 training examples processsed\n",
      "224001 training examples processsed\n",
      "225001 training examples processsed\n",
      "226001 training examples processsed\n",
      "227001 training examples processsed\n",
      "228001 training examples processsed\n",
      "229001 training examples processsed\n",
      "230001 training examples processsed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231001 training examples processsed\n",
      "232001 training examples processsed\n",
      "233001 training examples processsed\n",
      "234001 training examples processsed\n",
      "235001 training examples processsed\n",
      "236001 training examples processsed\n",
      "237001 training examples processsed\n",
      "238001 training examples processsed\n",
      "239001 training examples processsed\n",
      "240001 training examples processsed\n",
      "241001 training examples processsed\n",
      "242001 training examples processsed\n",
      "243001 training examples processsed\n",
      "244001 training examples processsed\n",
      "245001 training examples processsed\n",
      "246001 training examples processsed\n",
      "247001 training examples processsed\n",
      "248001 training examples processsed\n",
      "249001 training examples processsed\n",
      "250001 training examples processsed\n",
      "251001 training examples processsed\n",
      "252001 training examples processsed\n",
      "253001 training examples processsed\n",
      "254001 training examples processsed\n",
      "255001 training examples processsed\n",
      "256001 training examples processsed\n",
      "257001 training examples processsed\n",
      "258001 training examples processsed\n",
      "259001 training examples processsed\n",
      "260001 training examples processsed\n",
      "261001 training examples processsed\n",
      "262001 training examples processsed\n",
      "263001 training examples processsed\n",
      "264001 training examples processsed\n",
      "265001 training examples processsed\n",
      "266001 training examples processsed\n",
      "267001 training examples processsed\n",
      "268001 training examples processsed\n",
      "269001 training examples processsed\n",
      "270001 training examples processsed\n",
      "271001 training examples processsed\n",
      "272001 training examples processsed\n",
      "273001 training examples processsed\n",
      "274001 training examples processsed\n",
      "275001 training examples processsed\n",
      "276001 training examples processsed\n",
      "277001 training examples processsed\n",
      "278001 training examples processsed\n",
      "279001 training examples processsed\n",
      "280001 training examples processsed\n",
      "281001 training examples processsed\n",
      "282001 training examples processsed\n",
      "283001 training examples processsed\n",
      "284001 training examples processsed\n",
      "285001 training examples processsed\n",
      "286001 training examples processsed\n",
      "287001 training examples processsed\n",
      "288001 training examples processsed\n",
      "289001 training examples processsed\n",
      "290001 training examples processsed\n",
      "291001 training examples processsed\n",
      "292001 training examples processsed\n",
      "293001 training examples processsed\n",
      "294001 training examples processsed\n",
      "295001 training examples processsed\n",
      "296001 training examples processsed\n",
      "297001 training examples processsed\n",
      "298001 training examples processsed\n",
      "299001 training examples processsed\n",
      "300001 training examples processsed\n",
      "301001 training examples processsed\n",
      "302001 training examples processsed\n",
      "303001 training examples processsed\n",
      "304001 training examples processsed\n",
      "305001 training examples processsed\n",
      "306001 training examples processsed\n",
      "307001 training examples processsed\n",
      "308001 training examples processsed\n",
      "309001 training examples processsed\n",
      "310001 training examples processsed\n",
      "311001 training examples processsed\n",
      "312001 training examples processsed\n",
      "313001 training examples processsed\n",
      "314001 training examples processsed\n",
      "315001 training examples processsed\n",
      "316001 training examples processsed\n",
      "317001 training examples processsed\n",
      "318001 training examples processsed\n",
      "319001 training examples processsed\n",
      "320001 training examples processsed\n",
      "321001 training examples processsed\n",
      "322001 training examples processsed\n",
      "323001 training examples processsed\n",
      "324001 training examples processsed\n",
      "325001 training examples processsed\n",
      "326001 training examples processsed\n",
      "327001 training examples processsed\n",
      "328001 training examples processsed\n",
      "329001 training examples processsed\n",
      "330001 training examples processsed\n",
      "331001 training examples processsed\n",
      "332001 training examples processsed\n",
      "333001 training examples processsed\n",
      "334001 training examples processsed\n",
      "335001 training examples processsed\n",
      "336001 training examples processsed\n",
      "337001 training examples processsed\n",
      "338001 training examples processsed\n",
      "339001 training examples processsed\n",
      "340001 training examples processsed\n",
      "341001 training examples processsed\n",
      "342001 training examples processsed\n",
      "343001 training examples processsed\n",
      "344001 training examples processsed\n",
      "345001 training examples processsed\n",
      "346001 training examples processsed\n",
      "347001 training examples processsed\n",
      "348001 training examples processsed\n",
      "349001 training examples processsed\n",
      "350001 training examples processsed\n",
      "351001 training examples processsed\n",
      "352001 training examples processsed\n",
      "353001 training examples processsed\n",
      "354001 training examples processsed\n",
      "355001 training examples processsed\n",
      "356001 training examples processsed\n",
      "357001 training examples processsed\n",
      "358001 training examples processsed\n",
      "359001 training examples processsed\n",
      "360001 training examples processsed\n",
      "361001 training examples processsed\n",
      "362001 training examples processsed\n",
      "363001 training examples processsed\n",
      "364001 training examples processsed\n",
      "365001 training examples processsed\n",
      "366001 training examples processsed\n",
      "367001 training examples processsed\n",
      "368001 training examples processsed\n",
      "369001 training examples processsed\n",
      "370001 training examples processsed\n",
      "371001 training examples processsed\n",
      "372001 training examples processsed\n",
      "373001 training examples processsed\n",
      "374001 training examples processsed\n",
      "375001 training examples processsed\n",
      "376001 training examples processsed\n",
      "377001 training examples processsed\n",
      "378001 training examples processsed\n",
      "379001 training examples processsed\n",
      "380001 training examples processsed\n",
      "381001 training examples processsed\n",
      "382001 training examples processsed\n",
      "383001 training examples processsed\n",
      "384001 training examples processsed\n",
      "385001 training examples processsed\n",
      "386001 training examples processsed\n",
      "387001 training examples processsed\n",
      "388001 training examples processsed\n",
      "389001 training examples processsed\n",
      "390001 training examples processsed\n",
      "391001 training examples processsed\n",
      "392001 training examples processsed\n",
      "393001 training examples processsed\n",
      "394001 training examples processsed\n",
      "395001 training examples processsed\n",
      "396001 training examples processsed\n",
      "397001 training examples processsed\n",
      "398001 training examples processsed\n",
      "399001 training examples processsed\n",
      "400001 training examples processsed\n",
      "401001 training examples processsed\n",
      "402001 training examples processsed\n",
      "403001 training examples processsed\n",
      "404001 training examples processsed\n",
      "405001 training examples processsed\n",
      "406001 training examples processsed\n",
      "407001 training examples processsed\n",
      "408001 training examples processsed\n",
      "409001 training examples processsed\n",
      "410001 training examples processsed\n",
      "411001 training examples processsed\n",
      "412001 training examples processsed\n",
      "413001 training examples processsed\n",
      "414001 training examples processsed\n",
      "415001 training examples processsed\n",
      "416001 training examples processsed\n",
      "417001 training examples processsed\n",
      "418001 training examples processsed\n",
      "419001 training examples processsed\n",
      "420001 training examples processsed\n",
      "421001 training examples processsed\n",
      "422001 training examples processsed\n",
      "423001 training examples processsed\n",
      "424001 training examples processsed\n",
      "425001 training examples processsed\n",
      "426001 training examples processsed\n",
      "427001 training examples processsed\n",
      "428001 training examples processsed\n",
      "429001 training examples processsed\n",
      "430001 training examples processsed\n",
      "431001 training examples processsed\n",
      "432001 training examples processsed\n",
      "433001 training examples processsed\n",
      "434001 training examples processsed\n",
      "435001 training examples processsed\n",
      "436001 training examples processsed\n",
      "437001 training examples processsed\n",
      "438001 training examples processsed\n",
      "439001 training examples processsed\n",
      "440001 training examples processsed\n",
      "441001 training examples processsed\n",
      "442001 training examples processsed\n",
      "443001 training examples processsed\n",
      "444001 training examples processsed\n",
      "445001 training examples processsed\n",
      "446001 training examples processsed\n",
      "447001 training examples processsed\n",
      "448001 training examples processsed\n",
      "449001 training examples processsed\n",
      "450001 training examples processsed\n",
      "451001 training examples processsed\n",
      "452001 training examples processsed\n",
      "453001 training examples processsed\n",
      "454001 training examples processsed\n",
      "455001 training examples processsed\n",
      "456001 training examples processsed\n",
      "457001 training examples processsed\n",
      "458001 training examples processsed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "459001 training examples processsed\n",
      "460001 training examples processsed\n",
      "461001 training examples processsed\n",
      "462001 training examples processsed\n",
      "463001 training examples processsed\n",
      "464001 training examples processsed\n",
      "465001 training examples processsed\n",
      "466001 training examples processsed\n",
      "467001 training examples processsed\n",
      "468001 training examples processsed\n",
      "469001 training examples processsed\n",
      "470001 training examples processsed\n",
      "471001 training examples processsed\n",
      "472001 training examples processsed\n",
      "473001 training examples processsed\n",
      "474001 training examples processsed\n",
      "475001 training examples processsed\n",
      "476001 training examples processsed\n",
      "477001 training examples processsed\n",
      "478001 training examples processsed\n",
      "479001 training examples processsed\n",
      "480001 training examples processsed\n",
      "481001 training examples processsed\n",
      "482001 training examples processsed\n",
      "483001 training examples processsed\n",
      "484001 training examples processsed\n",
      "485001 training examples processsed\n",
      "486001 training examples processsed\n",
      "487001 training examples processsed\n",
      "488001 training examples processsed\n",
      "489001 training examples processsed\n",
      "490001 training examples processsed\n",
      "491001 training examples processsed\n",
      "492001 training examples processsed\n",
      "493001 training examples processsed\n",
      "494001 training examples processsed\n",
      "495001 training examples processsed\n",
      "496001 training examples processsed\n",
      "497001 training examples processsed\n",
      "498001 training examples processsed\n",
      "499001 training examples processsed\n",
      "500001 training examples processsed\n",
      "501001 training examples processsed\n",
      "502001 training examples processsed\n",
      "503001 training examples processsed\n",
      "504001 training examples processsed\n",
      "505001 training examples processsed\n",
      "506001 training examples processsed\n",
      "507001 training examples processsed\n",
      "508001 training examples processsed\n",
      "509001 training examples processsed\n",
      "510001 training examples processsed\n",
      "511001 training examples processsed\n",
      "512001 training examples processsed\n",
      "513001 training examples processsed\n",
      "514001 training examples processsed\n",
      "515001 training examples processsed\n",
      "516001 training examples processsed\n",
      "517001 training examples processsed\n",
      "518001 training examples processsed\n",
      "519001 training examples processsed\n",
      "520001 training examples processsed\n",
      "521001 training examples processsed\n",
      "522001 training examples processsed\n",
      "523001 training examples processsed\n",
      "524001 training examples processsed\n",
      "525001 training examples processsed\n",
      "526001 training examples processsed\n",
      "527001 training examples processsed\n",
      "528001 training examples processsed\n",
      "529001 training examples processsed\n",
      "530001 training examples processsed\n",
      "531001 training examples processsed\n",
      "532001 training examples processsed\n",
      "533001 training examples processsed\n",
      "534001 training examples processsed\n",
      "535001 training examples processsed\n",
      "536001 training examples processsed\n",
      "537001 training examples processsed\n",
      "538001 training examples processsed\n",
      "539001 training examples processsed\n",
      "540001 training examples processsed\n",
      "541001 training examples processsed\n",
      "542001 training examples processsed\n",
      "543001 training examples processsed\n",
      "544001 training examples processsed\n",
      "545001 training examples processsed\n",
      "546001 training examples processsed\n",
      "547001 training examples processsed\n",
      "548001 training examples processsed\n",
      "549001 training examples processsed\n",
      "550001 training examples processsed\n",
      "551001 training examples processsed\n",
      "552001 training examples processsed\n",
      "553001 training examples processsed\n",
      "554001 training examples processsed\n",
      "555001 training examples processsed\n",
      "556001 training examples processsed\n",
      "557001 training examples processsed\n",
      "558001 training examples processsed\n",
      "559001 training examples processsed\n",
      "560001 training examples processsed\n",
      "561001 training examples processsed\n",
      "562001 training examples processsed\n",
      "563001 training examples processsed\n",
      "564001 training examples processsed\n",
      "565001 training examples processsed\n",
      "566001 training examples processsed\n",
      "567001 training examples processsed\n",
      "568001 training examples processsed\n",
      "569001 training examples processsed\n",
      "570001 training examples processsed\n",
      "571001 training examples processsed\n",
      "572001 training examples processsed\n",
      "573001 training examples processsed\n",
      "574001 training examples processsed\n",
      "575001 training examples processsed\n",
      "576001 training examples processsed\n",
      "577001 training examples processsed\n",
      "578001 training examples processsed\n",
      "579001 training examples processsed\n",
      "580001 training examples processsed\n",
      "581001 training examples processsed\n",
      "582001 training examples processsed\n",
      "583001 training examples processsed\n",
      "584001 training examples processsed\n",
      "585001 training examples processsed\n",
      "586001 training examples processsed\n",
      "587001 training examples processsed\n",
      "588001 training examples processsed\n",
      "589001 training examples processsed\n",
      "590001 training examples processsed\n",
      "591001 training examples processsed\n",
      "592001 training examples processsed\n",
      "593001 training examples processsed\n",
      "594001 training examples processsed\n",
      "595001 training examples processsed\n",
      "596001 training examples processsed\n",
      "597001 training examples processsed\n",
      "598001 training examples processsed\n",
      "599001 training examples processsed\n",
      "600001 training examples processsed\n",
      "601001 training examples processsed\n",
      "602001 training examples processsed\n",
      "603001 training examples processsed\n",
      "604001 training examples processsed\n",
      "605001 training examples processsed\n",
      "606001 training examples processsed\n",
      "607001 training examples processsed\n",
      "608001 training examples processsed\n",
      "609001 training examples processsed\n",
      "610001 training examples processsed\n",
      "611001 training examples processsed\n",
      "612001 training examples processsed\n",
      "613001 training examples processsed\n",
      "614001 training examples processsed\n",
      "615001 training examples processsed\n",
      "Wall time: 5h 51min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# we will use three basic features:\n",
    "\n",
    "# number of overlapping words in title\n",
    "overlap_title = []\n",
    "\n",
    "# number of overlapping words in abstract\n",
    "overlap_abstract = []\n",
    "\n",
    "# temporal distance between the papers\n",
    "temp_diff = []\n",
    "\n",
    "# number of common authors\n",
    "comm_auth = []\n",
    "\n",
    "# is in the same journal\n",
    "comm_journal = []\n",
    "\n",
    "# Cosine similarity between abstracts\n",
    "cos_similarity = []\n",
    "\n",
    "# Sum of authors in abstract\n",
    "author_abstract = []\n",
    "\n",
    "# LSA distance\n",
    "lsa_distance_euc = []\n",
    "\n",
    "counter = 0\n",
    "\n",
    "#preparation phase : \n",
    "for i in range(len(training_set)):\n",
    "    #print(\"skfjdzx\")\n",
    "    source = training_set[i][0]\n",
    "    target = training_set[i][1]\n",
    "\n",
    "    \n",
    "    index_source = IDs.index(source)\n",
    "    index_target = IDs.index(target)\n",
    "    \n",
    "    #print(index_source,index_target)\n",
    "    source_info = [element for element in node_info if int(element[0])==source][0]\n",
    "    target_info = [element for element in node_info if int(element[0])==target][0]\n",
    "\n",
    "    # convert to lowercase and tokenize\n",
    "    source_title = source_info[2].lower().split(\" \")\n",
    "    source_title = [token for token in source_title if token not in stpwds]\n",
    "    source_title = [stemmer.stem(token) for token in source_title]\n",
    "    \n",
    "    target_title = target_info[2].lower().split(\" \")\n",
    "    target_title = [token for token in target_title if token not in stpwds]\n",
    "    target_title = [stemmer.stem(token) for token in target_title]\n",
    "    \n",
    "    source_abstract = source_info[5].lower().split(\" \")\n",
    "    source_abstract = [token for token in source_abstract if token not in stpwds]\n",
    "    source_abstract = [stemmer.stem(token) for token in source_abstract]\n",
    "    \n",
    "    target_abstract = target_info[5].lower().split(\" \")\n",
    "    target_abstract = [token for token in target_abstract if token not in stpwds]\n",
    "    target_abstract = [stemmer.stem(token) for token in target_abstract]\n",
    "    \n",
    "    source_auth = source_info[3].split(\",\")\n",
    "    target_auth = target_info[3].split(\",\")\n",
    "      \n",
    "    source_auths = set(source_auth)\n",
    "    target_auths = set(target_auth)\n",
    "    \n",
    "    source_journal = source_info[4].split(\".\")\n",
    "    target_journal = target_info[4].split(\".\")\n",
    "    \n",
    "    #tfidf cosine similarity\n",
    "    tfidf_source = tfidf_matrix[index_source]# in case tfidf mat is so large that it's stored as a sparse matrix\n",
    "    tfidf_target = tfidf_matrix[index_target]# in case tfidf mat is so largs that it's stared as a sparse matrix\n",
    "    tfidf_sim    = cosine_similarity(tfidf_source, tfidf_source)[0][0]\n",
    "\n",
    "    author_abstract_count =0\n",
    "    author_abstract_count += len(source_auths.intersection(target_abstract))\n",
    "    author_abstract_count += len(target_auths.intersection(source_abstract))\n",
    "    \n",
    "    overlap_title.append(len(set(source_title).intersection(set(target_title))))\n",
    "    overlap_abstract.append(len(set(source_abstract).intersection(set(target_abstract))))\n",
    "    temp_diff.append(int(source_info[1]) - int(target_info[1]))\n",
    "    comm_auth.append(len(set(source_auth).intersection(set(target_auth))))\n",
    "    comm_journal.append(int(source_journal == target_journal))\n",
    "    cos_similarity.append(tfidf_sim)\n",
    "    author_abstract.append(author_abstract_count)\n",
    "    lsa_distance_euc.append(np.linalg.norm(LSA[index_source]-LSA[index_target] ))\n",
    "   \n",
    "    counter += 1\n",
    "    if counter % 1000 == True:\n",
    "        print(counter, \"training examples processsed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Title overlap'] = overlap_title\n",
    "train['Abstract overlap'] = overlap_abstract\n",
    "train['Temporal difference'] = temp_diff\n",
    "train['Common authors'] = comm_auth\n",
    "train['Common journal'] = comm_journal\n",
    "train['Cosine similarity'] = cos_similarity\n",
    "train['Authors in abstract'] = author_abstract\n",
    "train['LSA distance'] = lsa_distance_euc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A2 - Semantic features test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 testing examples processsed\n",
      "1001 testing examples processsed\n",
      "2001 testing examples processsed\n",
      "3001 testing examples processsed\n",
      "4001 testing examples processsed\n",
      "5001 testing examples processsed\n",
      "6001 testing examples processsed\n",
      "7001 testing examples processsed\n",
      "8001 testing examples processsed\n",
      "9001 testing examples processsed\n",
      "10001 testing examples processsed\n",
      "11001 testing examples processsed\n",
      "12001 testing examples processsed\n",
      "13001 testing examples processsed\n",
      "14001 testing examples processsed\n",
      "15001 testing examples processsed\n",
      "16001 testing examples processsed\n",
      "17001 testing examples processsed\n",
      "18001 testing examples processsed\n",
      "19001 testing examples processsed\n",
      "20001 testing examples processsed\n",
      "21001 testing examples processsed\n",
      "22001 testing examples processsed\n",
      "23001 testing examples processsed\n",
      "24001 testing examples processsed\n",
      "25001 testing examples processsed\n",
      "26001 testing examples processsed\n",
      "27001 testing examples processsed\n",
      "28001 testing examples processsed\n",
      "29001 testing examples processsed\n",
      "30001 testing examples processsed\n",
      "31001 testing examples processsed\n",
      "32001 testing examples processsed\n",
      "Wall time: 8min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# we will use these basic features:\n",
    "\n",
    "# number of overlapping words in title\n",
    "overlap_title_test = []\n",
    "\n",
    "# number of overlapping words in abstract\n",
    "overlap_abstract_test = []\n",
    "\n",
    "# temporal distance between the papers\n",
    "temp_diff_test = []\n",
    "\n",
    "# number of common authors\n",
    "comm_auth_test = []\n",
    "\n",
    "# is in the same journal\n",
    "comm_journal_test = []\n",
    "\n",
    "# Cosine similarity between abstracts\n",
    "cos_similarity_test = []\n",
    "\n",
    "# Sum of authors in abstract\n",
    "author_abstract_test = []\n",
    "\n",
    "# LSA distance\n",
    "lsa_distance_euc_test = []\n",
    "\n",
    "counter = 0\n",
    "\n",
    "#preparation phase : \n",
    "for i in range(len(testing_set)):\n",
    "#for i in xrange(len(testing_set_reduced)):\n",
    "    source = testing_set[i][0]\n",
    "    target = testing_set[i][1]\n",
    "    #source = testing_set_reduced[i][0]\n",
    "    #target = testing_set_reduced[i][1]\n",
    "\n",
    "    index_source = IDs.index(source)\n",
    "    index_target = IDs.index(target)\n",
    "    \n",
    "    source_info = [element for element in node_info if int(element[0])==source][0]\n",
    "    target_info = [element for element in node_info if int(element[0])==target][0]\n",
    "    \n",
    "    # convert to lowercase and tokenize\n",
    "    source_title = source_info[2].lower().split(\" \")\n",
    "    # remove stopwords\n",
    "    source_title = [token for token in source_title if token not in stpwds]\n",
    "    source_title = [stemmer.stem(token) for token in source_title]\n",
    "    \n",
    "    target_title = target_info[2].lower().split(\" \")\n",
    "    target_title = [token for token in target_title if token not in stpwds]\n",
    "    target_title = [stemmer.stem(token) for token in target_title]\n",
    "    \n",
    "    source_abstract = source_info[5].lower().split(\" \")\n",
    "    source_abstract = [token for token in source_abstract if token not in stpwds]\n",
    "    source_abstract = [stemmer.stem(token) for token in source_abstract]\n",
    "    \n",
    "    target_abstract = target_info[5].lower().split(\" \")\n",
    "    target_abstract = [token for token in target_abstract if token not in stpwds]\n",
    "    target_abstract = [stemmer.stem(token) for token in target_abstract]\n",
    "    \n",
    "    source_auth = source_info[3].split(\",\")\n",
    "    target_auth = target_info[3].split(\",\")\n",
    "    source_auths = set(source_auth)\n",
    "    target_auths = set(target_auth)\n",
    "    \n",
    "    source_journal = source_info[4].split(\".\")\n",
    "    target_journal = target_info[4].split(\".\")\n",
    "    \n",
    "    tfidf_source = tfidf_matrix[index_source]\n",
    "    tfidf_target = tfidf_matrix[index_target]\n",
    "    tfidf_sim    = cosine_similarity(tfidf_source, tfidf_target)[0][0]\n",
    "\n",
    "    author_abstract_count =0\n",
    "    author_abstract_count += len(source_auths.intersection(target_abstract))\n",
    "    author_abstract_count += len(target_auths.intersection(source_abstract))\n",
    "    \n",
    "    overlap_title_test.append(len(set(source_title).intersection(set(target_title))))\n",
    "    overlap_abstract_test.append(len(set(source_abstract).intersection(set(target_abstract))))\n",
    "    temp_diff_test.append(int(source_info[1]) - int(target_info[1]))\n",
    "    comm_auth_test.append(len(set(source_auth).intersection(set(target_auth))))\n",
    "    comm_journal_test.append(int(source_journal == target_journal))\n",
    "    cos_similarity_test.append(tfidf_sim)\n",
    "    author_abstract_test.append(author_abstract_count)\n",
    "    lsa_distance_euc_test.append(np.linalg.norm(LSA[index_source]-LSA[index_target] ))\n",
    "   \n",
    "    counter += 1\n",
    "    if counter % 1000 == True:\n",
    "        print(counter, \"testing examples processsed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Title overlap'] = overlap_title_test\n",
    "test['Abstract overlap'] = overlap_abstract_test\n",
    "test['Temporal difference'] = temp_diff_test\n",
    "test['Common authors'] = comm_auth_test\n",
    "test['Common journal'] = comm_journal_test\n",
    "test['Cosine similarity'] = cos_similarity_test\n",
    "test['Authors in abstract'] = author_abstract_test\n",
    "test['LSA distance'] = lsa_distance_euc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train_semantic.csv',index=False)\n",
    "test.to_csv('test_semantic.csv',index=False)\n",
    "# train = pd.read_csv('train_semantic.csv')\n",
    "# test =  pd.read_csv('test_semantic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Source</th>\n",
       "      <th>Edge</th>\n",
       "      <th>Title overlap</th>\n",
       "      <th>Abstract overlap</th>\n",
       "      <th>Temporal difference</th>\n",
       "      <th>Common authors</th>\n",
       "      <th>Common journal</th>\n",
       "      <th>Cosine similarity</th>\n",
       "      <th>Authors in abstract</th>\n",
       "      <th>LSA distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9510123</td>\n",
       "      <td>9502114</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.039132</td>\n",
       "      <td>0</td>\n",
       "      <td>0.176704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9707075</td>\n",
       "      <td>9604178</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015247</td>\n",
       "      <td>0</td>\n",
       "      <td>0.178874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9312155</td>\n",
       "      <td>9506142</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008888</td>\n",
       "      <td>0</td>\n",
       "      <td>0.278990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9911255</td>\n",
       "      <td>302165</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>-4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004740</td>\n",
       "      <td>0</td>\n",
       "      <td>0.325877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9701033</td>\n",
       "      <td>209076</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>-5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027379</td>\n",
       "      <td>0</td>\n",
       "      <td>0.230838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Target   Source  Edge  Title overlap  Abstract overlap  \\\n",
       "0  9510123  9502114     1              2                 4   \n",
       "1  9707075  9604178     1              1                 7   \n",
       "2  9312155  9506142     0              0                 6   \n",
       "3  9911255   302165     0              0                 8   \n",
       "4  9701033   209076     0              0                 8   \n",
       "\n",
       "   Temporal difference  Common authors  Common journal  Cosine similarity  \\\n",
       "0                    0               0               1           0.039132   \n",
       "1                    1               0               0           0.015247   \n",
       "2                   -2               0               0           0.008888   \n",
       "3                   -4               0               0           0.004740   \n",
       "4                   -5               0               0           0.027379   \n",
       "\n",
       "   Authors in abstract  LSA distance  \n",
       "0                    0      0.176704  \n",
       "1                    0      0.178874  \n",
       "2                    0      0.278990  \n",
       "3                    0      0.325877  \n",
       "4                    0      0.230838  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Source</th>\n",
       "      <th>Title overlap</th>\n",
       "      <th>Abstract overlap</th>\n",
       "      <th>Temporal difference</th>\n",
       "      <th>Common authors</th>\n",
       "      <th>Common journal</th>\n",
       "      <th>Cosine similarity</th>\n",
       "      <th>Authors in abstract</th>\n",
       "      <th>LSA distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9807076</td>\n",
       "      <td>9807139</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.055452</td>\n",
       "      <td>0</td>\n",
       "      <td>0.149897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109162</td>\n",
       "      <td>1182</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.110670</td>\n",
       "      <td>0</td>\n",
       "      <td>0.246126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9702187</td>\n",
       "      <td>9510135</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.043831</td>\n",
       "      <td>0</td>\n",
       "      <td>0.280983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>111048</td>\n",
       "      <td>110115</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.054856</td>\n",
       "      <td>0</td>\n",
       "      <td>0.246031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9910176</td>\n",
       "      <td>9410073</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.147222</td>\n",
       "      <td>0</td>\n",
       "      <td>0.203470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Target   Source  Title overlap  Abstract overlap  Temporal difference  \\\n",
       "0  9807076  9807139              0                 7                    0   \n",
       "1   109162     1182              2                 6                    1   \n",
       "2  9702187  9510135              1                 4                    2   \n",
       "3   111048   110115              1                13                    0   \n",
       "4  9910176  9410073              0                 4                    5   \n",
       "\n",
       "   Common authors  Common journal  Cosine similarity  Authors in abstract  \\\n",
       "0               0               0           0.055452                    0   \n",
       "1               0               1           0.110670                    0   \n",
       "2               0               1           0.043831                    0   \n",
       "3               0               1           0.054856                    0   \n",
       "4               0               0           0.147222                    0   \n",
       "\n",
       "   LSA distance  \n",
       "0      0.149897  \n",
       "1      0.246126  \n",
       "2      0.280983  \n",
       "3      0.246031  \n",
       "4      0.203470  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2b\"></a>\n",
    "### B - Topological features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using basic igraph library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## the following shows how to construct a graph with igraph\n",
    "## even though in this baseline we don't use it\n",
    "## look at http://igraph.org/python/doc/igraph.Graph-class.html for feature ideas\n",
    "edges = [(element[0],element[1]) for element in training_set if element[2]==\"1\"]\n",
    "\n",
    "## some nodes may not be connected to any other node\n",
    "## hence the need to create the nodes of the graph from node_info.csv,\n",
    "## not just from the edge list\n",
    "nodes = IDs\n",
    "\n",
    "#create empty directed graph\n",
    "g = igraph.Graph(directed=True)\n",
    " \n",
    "## add vertices\n",
    "g.add_vertices(nodes)\n",
    " \n",
    "## add edges\n",
    "g.add_edges(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 27.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "betweenness_info = g.betweenness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rkroc\\Anaconda3\\lib\\site-packages\\igraph\\__init__.py:1281: RuntimeWarning: This method was developed for undirected graphs at src/community/leading_eigenvector.c:530\n",
      "  membership, _, q = GraphBase.community_leading_eigenvector(\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "communities = g.community_leading_eigenvector()\n",
    "cluster_info = communities.membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pageranks=g.personalized_pagerank(damping=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TOPOLOGICAL Feature train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 training examples processsed\n",
      "10001 training examples processsed\n",
      "20001 training examples processsed\n",
      "30001 training examples processsed\n",
      "40001 training examples processsed\n",
      "50001 training examples processsed\n",
      "60001 training examples processsed\n",
      "70001 training examples processsed\n",
      "80001 training examples processsed\n",
      "90001 training examples processsed\n",
      "100001 training examples processsed\n",
      "110001 training examples processsed\n",
      "120001 training examples processsed\n",
      "130001 training examples processsed\n",
      "140001 training examples processsed\n",
      "150001 training examples processsed\n",
      "160001 training examples processsed\n",
      "170001 training examples processsed\n",
      "180001 training examples processsed\n",
      "190001 training examples processsed\n",
      "200001 training examples processsed\n",
      "210001 training examples processsed\n",
      "220001 training examples processsed\n",
      "230001 training examples processsed\n",
      "240001 training examples processsed\n",
      "250001 training examples processsed\n",
      "260001 training examples processsed\n",
      "270001 training examples processsed\n",
      "280001 training examples processsed\n",
      "290001 training examples processsed\n",
      "300001 training examples processsed\n",
      "310001 training examples processsed\n",
      "320001 training examples processsed\n",
      "330001 training examples processsed\n",
      "340001 training examples processsed\n",
      "350001 training examples processsed\n",
      "360001 training examples processsed\n",
      "370001 training examples processsed\n",
      "380001 training examples processsed\n",
      "390001 training examples processsed\n",
      "400001 training examples processsed\n",
      "410001 training examples processsed\n",
      "420001 training examples processsed\n",
      "430001 training examples processsed\n",
      "440001 training examples processsed\n",
      "450001 training examples processsed\n",
      "460001 training examples processsed\n",
      "470001 training examples processsed\n",
      "480001 training examples processsed\n",
      "490001 training examples processsed\n",
      "500001 training examples processsed\n",
      "510001 training examples processsed\n",
      "520001 training examples processsed\n",
      "530001 training examples processsed\n",
      "540001 training examples processsed\n",
      "550001 training examples processsed\n",
      "560001 training examples processsed\n",
      "570001 training examples processsed\n",
      "580001 training examples processsed\n",
      "590001 training examples processsed\n",
      "600001 training examples processsed\n",
      "610001 training examples processsed\n",
      "Wall time: 1h 34min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Betweenness centrality\n",
    "bet_centrality = []\n",
    "\n",
    "# Is same cluster\n",
    "is_same_cluster = []\n",
    "\n",
    "\n",
    "#Page rank\n",
    "page_rank=[]\n",
    "\n",
    "counter = 0\n",
    "\n",
    "#preparation phase : \n",
    "for i in range(len(training_set)):\n",
    "#for i in xrange(len(training_set_reduced)):\n",
    "    source = training_set[i][0]\n",
    "    target = training_set[i][1]\n",
    "    #source = training_set_reduced[i][0]\n",
    "    #target = training_set_reduced[i][1]\n",
    "\n",
    "    index_source = IDs.index(source)\n",
    "    index_target = IDs.index(target)\n",
    "    \n",
    "    betweenness_source = betweenness_info[index_source]\n",
    "    betweenness_target = betweenness_info[index_target]\n",
    "    \n",
    "    source_page_rank=pageranks[index_source]\n",
    "    target_page_rank=pageranks[index_target]\n",
    "    \n",
    "    bet_centrality.append(betweenness_source - betweenness_target)\n",
    "    is_same_cluster.append(int(cluster_info[index_source] == cluster_info[index_target]))\n",
    "    page_rank.append(source_page_rank+target_page_rank)\n",
    "   \n",
    "    counter += 1\n",
    "    if counter % 10000 == True:\n",
    "        print(counter, \"training examples processsed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Betweenness centrality'] = bet_centrality\n",
    "train['Same cluster'] = is_same_cluster\n",
    "train['Page rank'] = page_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TOPOLOGICAL Feature test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 testing examples processsed\n",
      "1001 testing examples processsed\n",
      "2001 testing examples processsed\n",
      "3001 testing examples processsed\n",
      "4001 testing examples processsed\n",
      "5001 testing examples processsed\n",
      "6001 testing examples processsed\n",
      "7001 testing examples processsed\n",
      "8001 testing examples processsed\n",
      "9001 testing examples processsed\n",
      "10001 testing examples processsed\n",
      "11001 testing examples processsed\n",
      "12001 testing examples processsed\n",
      "13001 testing examples processsed\n",
      "14001 testing examples processsed\n",
      "15001 testing examples processsed\n",
      "16001 testing examples processsed\n",
      "17001 testing examples processsed\n",
      "18001 testing examples processsed\n",
      "19001 testing examples processsed\n",
      "20001 testing examples processsed\n",
      "21001 testing examples processsed\n",
      "22001 testing examples processsed\n",
      "23001 testing examples processsed\n",
      "24001 testing examples processsed\n",
      "25001 testing examples processsed\n",
      "26001 testing examples processsed\n",
      "27001 testing examples processsed\n",
      "28001 testing examples processsed\n",
      "29001 testing examples processsed\n",
      "30001 testing examples processsed\n",
      "31001 testing examples processsed\n",
      "32001 testing examples processsed\n",
      "Wall time: 41.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Betweenness centrality\n",
    "bet_centrality_test = []\n",
    "\n",
    "# Is same cluster\n",
    "is_same_cluster_test = []\n",
    "\n",
    "\n",
    "#Page rank\n",
    "page_rank_test=[]\n",
    "\n",
    "counter = 0\n",
    "\n",
    "#preparation phase : \n",
    "for i in range(len(testing_set)):\n",
    "#for i in xrange(len(testing_set_reduced)):\n",
    "    source = testing_set[i][0]\n",
    "    target = testing_set[i][1]\n",
    "    #source = testing_set_reduced[i][0]\n",
    "    #target = testing_set_reduced[i][1]\n",
    "\n",
    "    index_source = IDs.index(source)\n",
    "    index_target = IDs.index(target)\n",
    "    \n",
    "    betweenness_source = betweenness_info[index_source]\n",
    "    betweenness_target = betweenness_info[index_target]\n",
    "    \n",
    "    source_page_rank=pageranks[index_source]\n",
    "    target_page_rank=pageranks[index_target]\n",
    "    \n",
    "    bet_centrality_test.append(betweenness_source - betweenness_target)\n",
    "    is_same_cluster_test.append(int(cluster_info[index_source] == cluster_info[index_target]))\n",
    "    page_rank_test.append(source_page_rank+target_page_rank)\n",
    "   \n",
    "    counter += 1\n",
    "    if counter % 1000 == True:\n",
    "        print(counter, \"testing examples processsed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Betweenness centrality'] = bet_centrality_test\n",
    "test['Same cluster'] = is_same_cluster_test\n",
    "test['Page rank'] = page_rank_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train_semantic_topo1.csv',index=False)\n",
    "test.to_csv('test_semantic_topo1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Source</th>\n",
       "      <th>Edge</th>\n",
       "      <th>Title overlap</th>\n",
       "      <th>Abstract overlap</th>\n",
       "      <th>Temporal difference</th>\n",
       "      <th>Common authors</th>\n",
       "      <th>Common journal</th>\n",
       "      <th>Cosine similarity</th>\n",
       "      <th>Authors in abstract</th>\n",
       "      <th>LSA distance</th>\n",
       "      <th>Betweenness centrality</th>\n",
       "      <th>Same cluster</th>\n",
       "      <th>Page rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9510123</td>\n",
       "      <td>9502114</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.039132</td>\n",
       "      <td>0</td>\n",
       "      <td>0.176704</td>\n",
       "      <td>8166.884091</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9707075</td>\n",
       "      <td>9604178</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015247</td>\n",
       "      <td>0</td>\n",
       "      <td>0.178874</td>\n",
       "      <td>31162.082411</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9312155</td>\n",
       "      <td>9506142</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008888</td>\n",
       "      <td>0</td>\n",
       "      <td>0.278990</td>\n",
       "      <td>-10559.734281</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9911255</td>\n",
       "      <td>302165</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>-4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004740</td>\n",
       "      <td>0</td>\n",
       "      <td>0.325877</td>\n",
       "      <td>611.223395</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9701033</td>\n",
       "      <td>209076</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>-5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027379</td>\n",
       "      <td>0</td>\n",
       "      <td>0.230838</td>\n",
       "      <td>-501.379284</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Target   Source  Edge  Title overlap  Abstract overlap  \\\n",
       "0  9510123  9502114     1              2                 4   \n",
       "1  9707075  9604178     1              1                 7   \n",
       "2  9312155  9506142     0              0                 6   \n",
       "3  9911255   302165     0              0                 8   \n",
       "4  9701033   209076     0              0                 8   \n",
       "\n",
       "   Temporal difference  Common authors  Common journal  Cosine similarity  \\\n",
       "0                    0               0               1           0.039132   \n",
       "1                    1               0               0           0.015247   \n",
       "2                   -2               0               0           0.008888   \n",
       "3                   -4               0               0           0.004740   \n",
       "4                   -5               0               0           0.027379   \n",
       "\n",
       "   Authors in abstract  LSA distance  Betweenness centrality  Same cluster  \\\n",
       "0                    0      0.176704             8166.884091             0   \n",
       "1                    0      0.178874            31162.082411             1   \n",
       "2                    0      0.278990           -10559.734281             1   \n",
       "3                    0      0.325877              611.223395             0   \n",
       "4                    0      0.230838             -501.379284             1   \n",
       "\n",
       "   Page rank  \n",
       "0   0.000058  \n",
       "1   0.000144  \n",
       "2   0.000049  \n",
       "3   0.000044  \n",
       "4   0.000157  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Source</th>\n",
       "      <th>Title overlap</th>\n",
       "      <th>Abstract overlap</th>\n",
       "      <th>Temporal difference</th>\n",
       "      <th>Common authors</th>\n",
       "      <th>Common journal</th>\n",
       "      <th>Cosine similarity</th>\n",
       "      <th>Authors in abstract</th>\n",
       "      <th>LSA distance</th>\n",
       "      <th>Betweenness centrality</th>\n",
       "      <th>Same cluster</th>\n",
       "      <th>Page rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9807076</td>\n",
       "      <td>9807139</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.055452</td>\n",
       "      <td>0</td>\n",
       "      <td>0.149897</td>\n",
       "      <td>2.136205e+05</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109162</td>\n",
       "      <td>1182</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.110670</td>\n",
       "      <td>0</td>\n",
       "      <td>0.246126</td>\n",
       "      <td>1.121793e+06</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9702187</td>\n",
       "      <td>9510135</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.043831</td>\n",
       "      <td>0</td>\n",
       "      <td>0.280983</td>\n",
       "      <td>2.305727e+05</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>111048</td>\n",
       "      <td>110115</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.054856</td>\n",
       "      <td>0</td>\n",
       "      <td>0.246031</td>\n",
       "      <td>6.989486e+05</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9910176</td>\n",
       "      <td>9410073</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.147222</td>\n",
       "      <td>0</td>\n",
       "      <td>0.203470</td>\n",
       "      <td>-2.600592e+04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Target   Source  Title overlap  Abstract overlap  Temporal difference  \\\n",
       "0  9807076  9807139              0                 7                    0   \n",
       "1   109162     1182              2                 6                    1   \n",
       "2  9702187  9510135              1                 4                    2   \n",
       "3   111048   110115              1                13                    0   \n",
       "4  9910176  9410073              0                 4                    5   \n",
       "\n",
       "   Common authors  Common journal  Cosine similarity  Authors in abstract  \\\n",
       "0               0               0           0.055452                    0   \n",
       "1               0               1           0.110670                    0   \n",
       "2               0               1           0.043831                    0   \n",
       "3               0               1           0.054856                    0   \n",
       "4               0               0           0.147222                    0   \n",
       "\n",
       "   LSA distance  Betweenness centrality  Same cluster  Page rank  \n",
       "0      0.149897            2.136205e+05             0   0.000086  \n",
       "1      0.246126            1.121793e+06             1   0.000160  \n",
       "2      0.280983            2.305727e+05             0   0.001309  \n",
       "3      0.246031            6.989486e+05             1   0.000052  \n",
       "4      0.203470           -2.600592e+04             0   0.000345  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the more advanced library networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(X, y):\n",
    "    graph = nx.Graph()\n",
    "    edges=[]\n",
    "    nodes=set()\n",
    "    for i in range(len(X)):\n",
    "        source = X[i][0]\n",
    "        target = X[i][1]\n",
    "        nodes.add(source)\n",
    "        nodes.add(target)\n",
    "        if y[i]==1:\n",
    "            edges.append((source, target))\n",
    "    graph.add_nodes_from(nodes)\n",
    "    graph.add_edges_from(edges)\n",
    "    return graph\n",
    "\n",
    "def create_directed_graph(X, y):\n",
    "    graph = nx.DiGraph()\n",
    "    edges=[]\n",
    "    nodes=set()\n",
    "    for i in range(len(X)):\n",
    "        source = X[i][0]\n",
    "        target = X[i][1]\n",
    "        nodes.add(source)\n",
    "        nodes.add(target)\n",
    "        if y[i]==1:\n",
    "            edges.append((source, target))\n",
    "    graph.add_nodes_from(nodes)\n",
    "    graph.add_edges_from(edges)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### topological feature train part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X = train[['Target', 'Source']].values\n",
    "y = train[['Edge']].values\n",
    "graph = create_graph(X,y) \n",
    "\n",
    "res_alloc_index = np.asarray(list(nx.resource_allocation_index(graph, X)))[:,2]\n",
    "jac_coef = np.asarray(list(nx.jaccard_coefficient(graph, X)))[:,2]\n",
    "ad_adar_idx = np.asarray(list(nx.adamic_adar_index(graph, X)))[:,2]\n",
    "pref_att = np.asarray(list(nx.preferential_attachment(graph, X)))[:,2]\n",
    "\n",
    "train['Ressource allocation'] = list(res_alloc_index)\n",
    "train['Jaccard coefficient'] = list(jac_coef)\n",
    "train['Adamic Adar'] = list(ad_adar_idx)\n",
    "train['Preferential attachment'] = list(pref_att)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### topological feature test part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 24.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_test = test[['Target', 'Source']].values\n",
    "\n",
    "res_alloc_index_test = np.asarray(list(nx.resource_allocation_index(graph, X_test)))[:,2]\n",
    "jac_coef_test = np.asarray(list(nx.jaccard_coefficient(graph, X_test)))[:,2]\n",
    "ad_adar_idx_test = np.asarray(list(nx.adamic_adar_index(graph, X_test)))[:,2]\n",
    "pref_att_test = np.asarray(list(nx.preferential_attachment(graph, X_test)))[:,2]\n",
    "\n",
    "test['Ressource allocation'] = list(res_alloc_index_test)\n",
    "test['Jaccard coefficient'] = list(jac_coef_test)\n",
    "test['Adamic Adar'] = list(ad_adar_idx_test)\n",
    "test['Preferential attachment'] = list(pref_att_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train_semantic_topo2.csv',index=False)\n",
    "test.to_csv('test_semantic_topo2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Source</th>\n",
       "      <th>Edge</th>\n",
       "      <th>Title overlap</th>\n",
       "      <th>Abstract overlap</th>\n",
       "      <th>Temporal difference</th>\n",
       "      <th>Common authors</th>\n",
       "      <th>Common journal</th>\n",
       "      <th>Cosine similarity</th>\n",
       "      <th>Authors in abstract</th>\n",
       "      <th>LSA distance</th>\n",
       "      <th>Betweenness centrality</th>\n",
       "      <th>Same cluster</th>\n",
       "      <th>Page rank</th>\n",
       "      <th>Ressource allocation</th>\n",
       "      <th>Jaccard coefficient</th>\n",
       "      <th>Adamic Adar</th>\n",
       "      <th>Preferential attachment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9510123</td>\n",
       "      <td>9502114</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.039132</td>\n",
       "      <td>0</td>\n",
       "      <td>0.176704</td>\n",
       "      <td>8166.884091</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.513898</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9707075</td>\n",
       "      <td>9604178</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015247</td>\n",
       "      <td>0</td>\n",
       "      <td>0.178874</td>\n",
       "      <td>31162.082411</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.226401</td>\n",
       "      <td>0.097087</td>\n",
       "      <td>4.320366</td>\n",
       "      <td>11613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9312155</td>\n",
       "      <td>9506142</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008888</td>\n",
       "      <td>0</td>\n",
       "      <td>0.278990</td>\n",
       "      <td>-10559.734281</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9911255</td>\n",
       "      <td>302165</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>-4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004740</td>\n",
       "      <td>0</td>\n",
       "      <td>0.325877</td>\n",
       "      <td>611.223395</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9701033</td>\n",
       "      <td>209076</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>-5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027379</td>\n",
       "      <td>0</td>\n",
       "      <td>0.230838</td>\n",
       "      <td>-501.379284</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Target   Source  Edge  Title overlap  Abstract overlap  \\\n",
       "0  9510123  9502114     1              2                 4   \n",
       "1  9707075  9604178     1              1                 7   \n",
       "2  9312155  9506142     0              0                 6   \n",
       "3  9911255   302165     0              0                 8   \n",
       "4  9701033   209076     0              0                 8   \n",
       "\n",
       "   Temporal difference  Common authors  Common journal  Cosine similarity  \\\n",
       "0                    0               0               1           0.039132   \n",
       "1                    1               0               0           0.015247   \n",
       "2                   -2               0               0           0.008888   \n",
       "3                   -4               0               0           0.004740   \n",
       "4                   -5               0               0           0.027379   \n",
       "\n",
       "   Authors in abstract  LSA distance  Betweenness centrality  Same cluster  \\\n",
       "0                    0      0.176704             8166.884091             0   \n",
       "1                    0      0.178874            31162.082411             1   \n",
       "2                    0      0.278990           -10559.734281             1   \n",
       "3                    0      0.325877              611.223395             0   \n",
       "4                    0      0.230838             -501.379284             1   \n",
       "\n",
       "   Page rank  Ressource allocation  Jaccard coefficient  Adamic Adar  \\\n",
       "0   0.000058              0.142857             0.058824     0.513898   \n",
       "1   0.000144              0.226401             0.097087     4.320366   \n",
       "2   0.000049              0.000000             0.000000     0.000000   \n",
       "3   0.000044              0.000000             0.000000     0.000000   \n",
       "4   0.000157              0.000000             0.000000     0.000000   \n",
       "\n",
       "   Preferential attachment  \n",
       "0                       72  \n",
       "1                    11613  \n",
       "2                        5  \n",
       "3                      280  \n",
       "4                      168  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### topological feature train part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating graph\n",
      "Generating vertex features\n",
      "0 615512\n",
      "0.0\n",
      "10000 615512\n",
      "1.0940577983856201\n",
      "20000 615512\n",
      "1.088376522064209\n",
      "30000 615512\n",
      "1.0729472637176514\n",
      "40000 615512\n",
      "1.0806050300598145\n",
      "50000 615512\n",
      "1.0903539657592773\n",
      "60000 615512\n",
      "1.086927890777588\n",
      "70000 615512\n",
      "1.0824799537658691\n",
      "80000 615512\n",
      "1.0766847133636475\n",
      "90000 615512\n",
      "1.125166416168213\n",
      "100000 615512\n",
      "1.0938587188720703\n",
      "110000 615512\n",
      "1.168952465057373\n",
      "120000 615512\n",
      "1.0457518100738525\n",
      "130000 615512\n",
      "1.0962486267089844\n",
      "140000 615512\n",
      "1.0635712146759033\n",
      "150000 615512\n",
      "1.076563835144043\n",
      "160000 615512\n",
      "1.0373296737670898\n",
      "170000 615512\n",
      "1.0600595474243164\n",
      "180000 615512\n",
      "1.0586533546447754\n",
      "190000 615512\n",
      "1.0809354782104492\n",
      "200000 615512\n",
      "1.0812690258026123\n",
      "210000 615512\n",
      "1.0504188537597656\n",
      "220000 615512\n",
      "1.0547397136688232\n",
      "230000 615512\n",
      "1.0824577808380127\n",
      "240000 615512\n",
      "1.0564625263214111\n",
      "250000 615512\n",
      "1.0427577495574951\n",
      "260000 615512\n",
      "1.0693409442901611\n",
      "270000 615512\n",
      "1.062920093536377\n",
      "280000 615512\n",
      "1.0592999458312988\n",
      "290000 615512\n",
      "1.0886385440826416\n",
      "300000 615512\n",
      "1.05684232711792\n",
      "310000 615512\n",
      "1.063342809677124\n",
      "320000 615512\n",
      "1.0623581409454346\n",
      "330000 615512\n",
      "1.0520117282867432\n",
      "340000 615512\n",
      "1.073415756225586\n",
      "350000 615512\n",
      "1.0740575790405273\n",
      "360000 615512\n",
      "1.0848889350891113\n",
      "370000 615512\n",
      "1.068493127822876\n",
      "380000 615512\n",
      "1.0638072490692139\n",
      "390000 615512\n",
      "1.0859863758087158\n",
      "400000 615512\n",
      "1.0871949195861816\n",
      "410000 615512\n",
      "1.0988092422485352\n",
      "420000 615512\n",
      "1.0755200386047363\n",
      "430000 615512\n",
      "1.1044080257415771\n",
      "440000 615512\n",
      "1.0811283588409424\n",
      "450000 615512\n",
      "1.0671160221099854\n",
      "460000 615512\n",
      "1.0785319805145264\n",
      "470000 615512\n",
      "1.0630035400390625\n",
      "480000 615512\n",
      "1.052633285522461\n",
      "490000 615512\n",
      "1.066080093383789\n",
      "500000 615512\n",
      "1.0427706241607666\n",
      "510000 615512\n",
      "1.0478291511535645\n",
      "520000 615512\n",
      "1.0622994899749756\n",
      "530000 615512\n",
      "1.0997087955474854\n",
      "540000 615512\n",
      "1.0695552825927734\n",
      "550000 615512\n",
      "1.1064364910125732\n",
      "560000 615512\n",
      "1.0685155391693115\n",
      "570000 615512\n",
      "1.0722670555114746\n",
      "580000 615512\n",
      "1.0742743015289307\n",
      "590000 615512\n",
      "1.080486536026001\n",
      "600000 615512\n",
      "1.06671142578125\n",
      "610000 615512\n",
      "1.077199935913086\n"
     ]
    }
   ],
   "source": [
    "def neighbor_calc(graph, v):\n",
    "    neighbors_in = graph.predecessors(v)\n",
    "    neighbors_out = graph.successors(v)\n",
    "    neighbors = list(set(neighbors_in).union(neighbors_out))\n",
    "   \n",
    "    return graph.in_degree(v), graph.out_degree(v), neighbors_in, neighbors_out, neighbors\n",
    "        \n",
    "            \n",
    "X = train[['Target', 'Source']].values\n",
    "y = train[['Edge']].values\n",
    "target_feats=np.empty((train.shape[0], 2))\n",
    "source_feats=np.empty((train.shape[0], 2))\n",
    "edge_feats=np.empty((train.shape[0], 2))\n",
    "print(\"Creating graph\")\n",
    "graph = create_directed_graph(X, y)\n",
    "print(\"Generating vertex features\")\n",
    "l = X.shape[0]\n",
    "t1 = time()\n",
    "for i, x in enumerate(X):\n",
    "    t=x[0]\n",
    "    s=x[1]\n",
    "    in_d_t, out_d_t, n_in_t, n_out_t, n_t = neighbor_calc(graph, t)\n",
    "    in_d_s, out_d_s, n_in_s, n_out_s, n_s = neighbor_calc(graph, s)\n",
    "    com_in = len(set(n_in_t).intersection(n_in_s))\n",
    "    com_on = len(set(n_out_t).intersection(n_out_s))\n",
    "\n",
    "    target_feats[i]=[in_d_t, out_d_t]\n",
    "    source_feats[i]=[in_d_s, out_d_s]\n",
    "    edge_feats[i]=[com_in, com_on]\n",
    "    if i%10000==0:\n",
    "        print(i, l)\n",
    "        t2=time()\n",
    "        print(t2-t1)\n",
    "        t1=t2\n",
    "\n",
    "train['Target_indegree'] = target_feats[:,0]\n",
    "train['Target_outdegree'] = target_feats[:,1]\n",
    "\n",
    "train['Source_indegree'] = source_feats[:,0]\n",
    "train['Source_outdegree'] = source_feats[:,1]\n",
    "\n",
    "train['Common_in'] = edge_feats[:,0]\n",
    "train['Common_out'] = edge_feats[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### topological feature test part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating graph\n",
      "Generating vertex features\n",
      "0 615512\n",
      "0.0\n",
      "10000 615512\n",
      "1.226555585861206\n",
      "20000 615512\n",
      "1.365011215209961\n",
      "30000 615512\n",
      "679.5116457939148\n",
      "Wall time: 11min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_test = test[['Target', 'Source']].values\n",
    "target_feats=np.empty((test.shape[0], 2))\n",
    "source_feats=np.empty((test.shape[0], 2))\n",
    "edge_feats=np.empty((test.shape[0], 2))\n",
    "t1 = time()\n",
    "print(\"Creating graph\")\n",
    "graph = create_directed_graph(X, y)\n",
    "print(\"Generating vertex features\")\n",
    "t1 = time()\n",
    "for i, x in enumerate(X_test):\n",
    "    t=x[0]\n",
    "    s=x[1]\n",
    "    in_d_t, out_d_t, n_in_t, n_out_t, n_t = neighbor_calc(graph, t)\n",
    "    in_d_s, out_d_s, n_in_s, n_out_s, n_s = neighbor_calc(graph, s)\n",
    "    com_in = len(set(n_in_t).intersection(n_in_s))\n",
    "    com_on = len(set(n_out_t).intersection(n_out_s))\n",
    "\n",
    "    target_feats[i]=[in_d_t, out_d_t]\n",
    "    source_feats[i]=[in_d_s, out_d_s]\n",
    "    edge_feats[i]=[com_in, com_on]\n",
    "    if i%10000==0:\n",
    "        print(i, l)\n",
    "        t2=time()\n",
    "        print(t2-t1)\n",
    "        t1=t2\n",
    "        \n",
    "test['Target_indegree'] = target_feats[:,0]\n",
    "test['Target_outdegree'] = target_feats[:,1]\n",
    "\n",
    "test['Source_indegree'] = source_feats[:,0]\n",
    "test['Source_outdegree'] = source_feats[:,1]\n",
    "\n",
    "test['Common_in'] = edge_feats[:,0]\n",
    "test['Common_out'] = edge_feats[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Source</th>\n",
       "      <th>Edge</th>\n",
       "      <th>Title overlap</th>\n",
       "      <th>Abstract overlap</th>\n",
       "      <th>Temporal difference</th>\n",
       "      <th>Common authors</th>\n",
       "      <th>Common journal</th>\n",
       "      <th>Cosine similarity</th>\n",
       "      <th>Authors in abstract</th>\n",
       "      <th>...</th>\n",
       "      <th>Ressource allocation</th>\n",
       "      <th>Jaccard coefficient</th>\n",
       "      <th>Adamic Adar</th>\n",
       "      <th>Preferential attachment</th>\n",
       "      <th>Target_indegree</th>\n",
       "      <th>Target_outdegree</th>\n",
       "      <th>Source_indegree</th>\n",
       "      <th>Source_outdegree</th>\n",
       "      <th>Common_in</th>\n",
       "      <th>Common_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9510123</td>\n",
       "      <td>9502114</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.039132</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.513898</td>\n",
       "      <td>72</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9707075</td>\n",
       "      <td>9604178</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015247</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.226401</td>\n",
       "      <td>0.097087</td>\n",
       "      <td>4.320366</td>\n",
       "      <td>11613</td>\n",
       "      <td>11.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9312155</td>\n",
       "      <td>9506142</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008888</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9911255</td>\n",
       "      <td>302165</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>-4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004740</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>280</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9701033</td>\n",
       "      <td>209076</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>-5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027379</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>168</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Target   Source  Edge  Title overlap  Abstract overlap  \\\n",
       "0  9510123  9502114     1              2                 4   \n",
       "1  9707075  9604178     1              1                 7   \n",
       "2  9312155  9506142     0              0                 6   \n",
       "3  9911255   302165     0              0                 8   \n",
       "4  9701033   209076     0              0                 8   \n",
       "\n",
       "   Temporal difference  Common authors  Common journal  Cosine similarity  \\\n",
       "0                    0               0               1           0.039132   \n",
       "1                    1               0               0           0.015247   \n",
       "2                   -2               0               0           0.008888   \n",
       "3                   -4               0               0           0.004740   \n",
       "4                   -5               0               0           0.027379   \n",
       "\n",
       "   Authors in abstract  ...  Ressource allocation  Jaccard coefficient  \\\n",
       "0                    0  ...              0.142857             0.058824   \n",
       "1                    0  ...              0.226401             0.097087   \n",
       "2                    0  ...              0.000000             0.000000   \n",
       "3                    0  ...              0.000000             0.000000   \n",
       "4                    0  ...              0.000000             0.000000   \n",
       "\n",
       "   Adamic Adar  Preferential attachment  Target_indegree  Target_outdegree  \\\n",
       "0     0.513898                       72              3.0               3.0   \n",
       "1     4.320366                    11613             11.0              68.0   \n",
       "2     0.000000                        5              1.0               0.0   \n",
       "3     0.000000                      280              4.0              16.0   \n",
       "4     0.000000                      168              7.0               0.0   \n",
       "\n",
       "   Source_indegree  Source_outdegree  Common_in  Common_out  \n",
       "0              8.0               4.0        0.0         0.0  \n",
       "1            124.0              23.0        0.0         0.0  \n",
       "2              2.0               3.0        0.0         0.0  \n",
       "3              2.0              12.0        0.0         0.0  \n",
       "4              2.0              22.0        0.0         0.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Source</th>\n",
       "      <th>Title overlap</th>\n",
       "      <th>Abstract overlap</th>\n",
       "      <th>Temporal difference</th>\n",
       "      <th>Common authors</th>\n",
       "      <th>Common journal</th>\n",
       "      <th>Cosine similarity</th>\n",
       "      <th>Authors in abstract</th>\n",
       "      <th>LSA distance</th>\n",
       "      <th>...</th>\n",
       "      <th>Ressource allocation</th>\n",
       "      <th>Jaccard coefficient</th>\n",
       "      <th>Adamic Adar</th>\n",
       "      <th>Preferential attachment</th>\n",
       "      <th>Target_indegree</th>\n",
       "      <th>Target_outdegree</th>\n",
       "      <th>Source_indegree</th>\n",
       "      <th>Source_outdegree</th>\n",
       "      <th>Common_in</th>\n",
       "      <th>Common_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9807076</td>\n",
       "      <td>9807139</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.055452</td>\n",
       "      <td>0</td>\n",
       "      <td>0.149897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1062</td>\n",
       "      <td>49.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109162</td>\n",
       "      <td>1182</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.110670</td>\n",
       "      <td>0</td>\n",
       "      <td>0.246126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.311535</td>\n",
       "      <td>0.074303</td>\n",
       "      <td>5.377973</td>\n",
       "      <td>13590</td>\n",
       "      <td>100.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9702187</td>\n",
       "      <td>9510135</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.043831</td>\n",
       "      <td>0</td>\n",
       "      <td>0.280983</td>\n",
       "      <td>...</td>\n",
       "      <td>1.342594</td>\n",
       "      <td>0.065338</td>\n",
       "      <td>15.053612</td>\n",
       "      <td>164797</td>\n",
       "      <td>209.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>726.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>111048</td>\n",
       "      <td>110115</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.054856</td>\n",
       "      <td>0</td>\n",
       "      <td>0.246031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.298419</td>\n",
       "      <td>0.221053</td>\n",
       "      <td>4.899424</td>\n",
       "      <td>3315</td>\n",
       "      <td>11.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9910176</td>\n",
       "      <td>9410073</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.147222</td>\n",
       "      <td>0</td>\n",
       "      <td>0.203470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Target   Source  Title overlap  Abstract overlap  Temporal difference  \\\n",
       "0  9807076  9807139              0                 7                    0   \n",
       "1   109162     1182              2                 6                    1   \n",
       "2  9702187  9510135              1                 4                    2   \n",
       "3   111048   110115              1                13                    0   \n",
       "4  9910176  9410073              0                 4                    5   \n",
       "\n",
       "   Common authors  Common journal  Cosine similarity  Authors in abstract  \\\n",
       "0               0               0           0.055452                    0   \n",
       "1               0               1           0.110670                    0   \n",
       "2               0               1           0.043831                    0   \n",
       "3               0               1           0.054856                    0   \n",
       "4               0               0           0.147222                    0   \n",
       "\n",
       "   LSA distance  ...  Ressource allocation  Jaccard coefficient  Adamic Adar  \\\n",
       "0      0.149897  ...              0.000000             0.000000     0.000000   \n",
       "1      0.246126  ...              0.311535             0.074303     5.377973   \n",
       "2      0.280983  ...              1.342594             0.065338    15.053612   \n",
       "3      0.246031  ...              0.298419             0.221053     4.899424   \n",
       "4      0.203470  ...              0.000000             0.000000     0.000000   \n",
       "\n",
       "   Preferential attachment  Target_indegree  Target_outdegree  \\\n",
       "0                     1062             49.0              10.0   \n",
       "1                    13590            100.0             203.0   \n",
       "2                   164797            209.0              14.0   \n",
       "3                     3315             11.0              40.0   \n",
       "4                     1050              1.0               6.0   \n",
       "\n",
       "   Source_indegree  Source_outdegree  Common_in  Common_out  \n",
       "0              3.0              15.0        0.0         0.0  \n",
       "1             39.0               6.0        0.0         0.0  \n",
       "2            726.0              13.0        0.0         0.0  \n",
       "3             16.0              49.0        0.0         0.0  \n",
       "4            144.0               6.0        0.0         0.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Source</th>\n",
       "      <th>Edge</th>\n",
       "      <th>Title overlap</th>\n",
       "      <th>Abstract overlap</th>\n",
       "      <th>Temporal difference</th>\n",
       "      <th>Common authors</th>\n",
       "      <th>Common journal</th>\n",
       "      <th>Cosine similarity</th>\n",
       "      <th>Authors in abstract</th>\n",
       "      <th>...</th>\n",
       "      <th>Ressource allocation</th>\n",
       "      <th>Jaccard coefficient</th>\n",
       "      <th>Adamic Adar</th>\n",
       "      <th>Preferential attachment</th>\n",
       "      <th>Target_indegree</th>\n",
       "      <th>Target_outdegree</th>\n",
       "      <th>Source_indegree</th>\n",
       "      <th>Source_outdegree</th>\n",
       "      <th>Common_in</th>\n",
       "      <th>Common_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9510123</td>\n",
       "      <td>9502114</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.039132</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.513898</td>\n",
       "      <td>72</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9707075</td>\n",
       "      <td>9604178</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015247</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.226401</td>\n",
       "      <td>0.097087</td>\n",
       "      <td>4.320366</td>\n",
       "      <td>11613</td>\n",
       "      <td>11.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9312155</td>\n",
       "      <td>9506142</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008888</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9911255</td>\n",
       "      <td>302165</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>-4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004740</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>280</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9701033</td>\n",
       "      <td>209076</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>-5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027379</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>168</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Target   Source  Edge  Title overlap  Abstract overlap  \\\n",
       "0  9510123  9502114     1              2                 4   \n",
       "1  9707075  9604178     1              1                 7   \n",
       "2  9312155  9506142     0              0                 6   \n",
       "3  9911255   302165     0              0                 8   \n",
       "4  9701033   209076     0              0                 8   \n",
       "\n",
       "   Temporal difference  Common authors  Common journal  Cosine similarity  \\\n",
       "0                    0               0               1           0.039132   \n",
       "1                    1               0               0           0.015247   \n",
       "2                   -2               0               0           0.008888   \n",
       "3                   -4               0               0           0.004740   \n",
       "4                   -5               0               0           0.027379   \n",
       "\n",
       "   Authors in abstract  ...  Ressource allocation  Jaccard coefficient  \\\n",
       "0                    0  ...              0.142857             0.058824   \n",
       "1                    0  ...              0.226401             0.097087   \n",
       "2                    0  ...              0.000000             0.000000   \n",
       "3                    0  ...              0.000000             0.000000   \n",
       "4                    0  ...              0.000000             0.000000   \n",
       "\n",
       "   Adamic Adar  Preferential attachment  Target_indegree  Target_outdegree  \\\n",
       "0     0.513898                       72              3.0               3.0   \n",
       "1     4.320366                    11613             11.0              68.0   \n",
       "2     0.000000                        5              1.0               0.0   \n",
       "3     0.000000                      280              4.0              16.0   \n",
       "4     0.000000                      168              7.0               0.0   \n",
       "\n",
       "   Source_indegree  Source_outdegree  Common_in  Common_out  \n",
       "0              8.0               4.0        0.0         0.0  \n",
       "1            124.0              23.0        0.0         0.0  \n",
       "2              2.0               3.0        0.0         0.0  \n",
       "3              2.0              12.0        0.0         0.0  \n",
       "4              2.0              22.0        0.0         0.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train_complete.csv',index=False)\n",
    "test.to_csv('test_complete.csv',index=False)\n",
    "# train = pd.read_csv('train_complete.csv',header=0)\n",
    "# test = pd.read_csv('test_complete.csv',header=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
